{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 파이토치로 구현한 RNN\n",
    "\n",
    "## 4-1. 영화리뷰 RNN(BasicGRU)으로 감정분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.6.0\n",
      "  Using cached torchtext-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from torchtext==0.6.0) (4.66.2)\n",
      "Requirement already satisfied: requests in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from torchtext==0.6.0) (2.31.0)\n",
      "Requirement already satisfied: torch in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from torchtext==0.6.0) (2.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from torchtext==0.6.0) (1.26.4)\n",
      "Requirement already satisfied: six in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from torchtext==0.6.0) (1.16.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from torchtext==0.6.0) (0.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from requests->torchtext==0.6.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from requests->torchtext==0.6.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from requests->torchtext==0.6.0) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from torch->torchtext==0.6.0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from torch->torchtext==0.6.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from torch->torchtext==0.6.0) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from torch->torchtext==0.6.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from torch->torchtext==0.6.0) (2023.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from tqdm->torchtext==0.6.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\higi4\\anaconda3\\envs\\env_deep3book\\lib\\site-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
      "Using cached torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Basic GRU model...\n",
      "[이폭: 1] 검증 오차:  0.59 | 검증 정확도: 71.32\n",
      "모델 저장\n",
      "[이폭: 2] 검증 오차:  0.36 | 검증 정확도: 84.62\n",
      "모델 저장\n",
      "[이폭: 3] 검증 오차:  0.39 | 검증 정확도: 84.82\n",
      "[이폭: 4] 검증 오차:  0.47 | 검증 정확도: 85.92\n",
      "[이폭: 5] 검증 오차:  0.67 | 검증 정확도: 83.26\n",
      "[이폭: 6] 검증 오차:  0.58 | 검증 정확도: 84.70\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import datasets,data\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "lr = 0.001\n",
    "EPOCHS = 6\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "## 데이터를 로드할때 어떻게 전처리를 진행할지를 정의하는 객체 Field\n",
    "### sequential : 시퀀스 데이터 여부 (텍스트 데이터의 경우 True)\n",
    "### batch_first : 미니배치 차원을 맨 앞으로 하여 데이터를 불러올지 여부 \n",
    "TEXT = data.Field(sequential=True,batch_first=True,lower=True)\n",
    "LABEL = data.Field(sequential=False,batch_first=True)\n",
    "\n",
    "trainset,testset = datasets.IMDB.splits(TEXT,LABEL)\n",
    "\n",
    "## 단어 사전을 만듬\n",
    "### min_freq = 5 : 최소 5번 이상 등장한 단어만을 사전에 담겠다는 의미\n",
    "### 5번 미만으로 출현하는 단어는 unk 토큰으로 대체\n",
    "TEXT.build_vocab(trainset, min_freq=5)\n",
    "LABEL.build_vocab(trainset)\n",
    "\n",
    "trainset,valset = trainset.split(split_ratio=0.8)\n",
    "\n",
    "## 반복자 생성 => 반복할때마다 배치를 생성시켜주는 반복자\n",
    "train_iter,val_iter,test_iter = data.BucketIterator.splits(\n",
    "    (trainset,valset,testset), batch_size=BATCH_SIZE, shuffle=True, repeat=False)\n",
    "\n",
    "vocab_size = len(TEXT.vocab)\n",
    "n_classes = 2\n",
    "\n",
    "class BasicGRU(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "        super(BasicGRU, self).__init__()\n",
    "        print(\"Building Basic GRU model...\")\n",
    "        self.n_layers = n_layers\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        ## RNN은 Vanishing gradient 문제가 발생할 수 있기 때문에 GRU를 사용\n",
    "        ## GRU는 시계열 데이터 속 벡터사이의 정보 전달량을 조절함으로써 기울기를 적정하게 유지하고 문장 앞부분의 정보가 끝까지 도달 할 수 있도록 도와줌\n",
    "        self.gru = nn.GRU(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        ## RNN은 입력데이터 X외에도 초기 은닉 상태를 입력해야함\n",
    "        h_0 = self._init_state(batch_size=x.size(0))\n",
    "        x, _ = self.gru(x, h_0)\n",
    "        ## 마지막 time-step의 hidden state를 추출 => 마지막 선형 layer 들어가기전 히든 스테이트\n",
    "        h_t = x[:,-1,:]\n",
    "        self.dropout(h_t)\n",
    "        logit = self.out(h_t)\n",
    "        return logit\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        ## parameters 함수는 그 신경망 모듈의 가중치 정보들을 반복자 형태로 반환\n",
    "        ## data 함수는 그 가중치(텐서) 정보들을 실제 값으로 반환\n",
    "        ## 즉 아래 코드는 gru 모듈의 첫번째 가중치 텐서(모델의 가중치 텐서와 같은 데이터 타입)를 추출함\n",
    "        weight = next(self.parameters()).data\n",
    "        ## new 함수는 텐서를 생성하는 함수\n",
    "        ## 모델의 가중치와 같은 모양(n_layers,batch_size,hidden_dim)의 텐서로 변환\n",
    "        ## 텐서의 모든 값을 0으로 초기화 => zero_() 함수\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()\n",
    "\n",
    "def train(model,optimizer,train_iter):\n",
    "    model.train()\n",
    "    for b, batch in enumerate(train_iter):\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        ## 모든 y 값에서 1을 빼는 것 ( 1,2 를 0,1로 변환)\n",
    "        y.data.sub_(1)\n",
    "        optimizer.zero_grad()\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate(model,eval_iter):\n",
    "    model.eval()\n",
    "    corrects, total_loss = 0, 0\n",
    "    for batch in eval_iter:\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1)\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y, reduction='sum')\n",
    "        total_loss += loss.item()\n",
    "        corrects += logit.max(1)[1].eq(y).sum().item()\n",
    "    size = len(eval_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, avg_accuracy\n",
    "\n",
    "model = BasicGRU(1,256,vocab_size,1278,n_classes,0.5).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "best_val_loss = None\n",
    "for e in range(1,EPOCHS+1):\n",
    "    train(model,optimizer,train_iter)\n",
    "    val_loss, val_accuracy = evaluate(model,val_iter)\n",
    "\n",
    "    print(\"[이폭: %d] 검증 오차: %5.2f | 검증 정확도: %5.2f\" % (e,val_loss,val_accuracy))\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        print(\"모델 저장\")\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(model.state_dict(),\"snapshot/txtclassification.pt\")\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-3. Seq2Seq 모델 구현하기 (미니 seq2seq)\n",
    " . 간단한 구현을 위해 미니 seq2seq를 구현하므로 일반적인 단어단위 인베딩이 아닌 글자 단위 캐릭터 임베딩을 사용   \n",
    " . 아스키 코드 사용 => 사전 토큰수 256(아스키 코드의 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 반복:0 오차:5.697714805603027\n",
      "['ñ', '¡', 'ô', 'Ü']\n",
      "\n",
      " 반복:100 오차:2.1441774368286133\n",
      "['h', 'h', 'l', 'a']\n",
      "\n",
      " 반복:200 오차:0.7406474947929382\n",
      "['h', 'h', 'l', 'a']\n",
      "\n",
      " 반복:300 오차:0.3772960603237152\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:400 오차:0.24323907494544983\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:500 오차:0.17518796026706696\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:600 오차:0.13386446237564087\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:700 오차:0.1063300222158432\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:800 오차:0.08686168491840363\n",
      "['h', 'o', 'l', 'a']\n",
      "\n",
      " 반복:900 오차:0.07248760014772415\n",
      "['h', 'o', 'l', 'a']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vocab_size = 256\n",
    "x_ = list(map(ord,\"hello\")) ## ord는 파이썬 내장 함수로 유니코드 코드 포인트를 나타내는 정수로 변환\n",
    "y_ = list(map(ord,\"hola\"))\n",
    "x = torch.LongTensor(x_)\n",
    "y = torch.LongTensor(y_)\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,vocab_size,hidden_size):\n",
    "        super(Seq2Seq,self).__init__()\n",
    "        self.n_layers = 1\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size,hidden_size)\n",
    "        self.encoder = nn.GRU(hidden_size,hidden_size)        \n",
    "        self.decoder = nn.GRU(hidden_size,hidden_size)\n",
    "        self.project = nn.Linear(hidden_size,vocab_size)\n",
    "    \n",
    "    def forward(self,inputs,targets):\n",
    "        initial_state = self._init_state()\n",
    "        embedding = self.embedding(inputs).unsqueeze(1) ## 1차원 추가\n",
    "        encoder_output, encoder_state = self.encoder(embedding,initial_state)\n",
    "        ## 문맥벡터 encoder_state랑 decoder_input을 넣어주면서 디코더를 돌림\n",
    "        ## 맨 처음 디코더 인풋은 문장 시작 토큰을 입력 데이터로 넣어야함 => 여기서는 0\n",
    "        decoder_state = encoder_state\n",
    "        decoder_input = torch.LongTensor([0])\n",
    "        outputs = []\n",
    "        ## 여기선 for문 사용\n",
    "        ## 실제 번역기에선 for문을 사용하지 않고 <en> <fr> <es> 등의 토큰을 사용하여 최종 출력을 얻음\n",
    "        for i in range(targets.size()[0]):\n",
    "            decoder_input = self.embedding(decoder_input).unsqueeze(1)\n",
    "            decoder_output, decoder_state = self.decoder(decoder_input,decoder_state)\n",
    "            ## 디코더의 출력을 선형 레이어를 통과시켜서 다음 단어를 예측\n",
    "            projection = self.project(decoder_output)\n",
    "            outputs.append(projection)\n",
    "            ## 티처 포싱 방법\n",
    "            ## 디코더의 출력을 다음 입력으로 넣어주는 것이 아니라 실제 목표값을 넣어주는 방법\n",
    "            ## 디코더의 출력을 넣어주어서 학습시키면 디코더의 출력값이 잘못된 값이 나올 수 도 있으므로\n",
    "            ## 학습이 느려진다. 그러므로 학습 때는 실제 정답을 넣어줘서 학습을 빨리 시킨다\n",
    "            ## 하지만 실제 예측할 때는 디코더의 출력값을 넣어줘야 한다!\n",
    "            decoder_input = torch.LongTensor([targets[i]])\n",
    "        outputs = torch.stack(outputs).squeeze()        \n",
    "        return outputs\n",
    "\n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_size).zero_()\n",
    "\n",
    "seq2seq = Seq2Seq(vocab_size,16)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(seq2seq.parameters(),lr=0.001)\n",
    "\n",
    "log = []\n",
    "for i in range(1000):\n",
    "    prediction = seq2seq(x,y)\n",
    "    loss = criterion(prediction,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_val = loss.data\n",
    "    log.append(loss_val)\n",
    "    if i % 100 == 0:\n",
    "        print(\"\\n 반복:%d 오차:%s\" % (i,loss_val.item()))\n",
    "        _, top1 = prediction.data.topk(1,1)\n",
    "        print([chr(c) for c in top1.squeeze().numpy().tolist()])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_deep3book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
